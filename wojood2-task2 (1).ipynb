{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8303505,"sourceType":"datasetVersion","datasetId":4932833},{"sourceId":8329960,"sourceType":"datasetVersion","datasetId":4946162}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ! pip install seqeval transformers datasets tokenizers seqeval evaluate\n! pip install seqeval","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-06T13:14:24.345267Z","iopub.execute_input":"2024-05-06T13:14:24.346069Z","iopub.status.idle":"2024-05-06T13:14:36.226801Z","shell.execute_reply.started":"2024-05-06T13:14:24.346036Z","shell.execute_reply":"2024-05-06T13:14:36.225580Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: seqeval in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport datasets\nimport json\nimport numpy as np \nimport pandas as pd\nimport torch\nimport os\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom datasets import load_dataset, Dataset\nfrom transformers import AutoConfig, AutoTokenizer, AutoModel, AutoModelForTokenClassification, BertConfig, DataCollatorForTokenClassification, BertTokenizerFast, TrainingArguments, Trainer, EarlyStoppingCallback\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-05-06T13:14:36.229406Z","iopub.execute_input":"2024-05-06T13:14:36.230246Z","iopub.status.idle":"2024-05-06T13:14:36.237021Z","shell.execute_reply.started":"2024-05-06T13:14:36.230182Z","shell.execute_reply":"2024-05-06T13:14:36.236082Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize_arabic(text):\n    alif_maksura_to_yeh = re.sub(r'[يى]', 'ي', text)\n    teh_marbuta_to_heh = re.sub(r'ة', 'ه', alif_maksura_to_yeh)\n    alifs_normalized = re.sub(r'[أإآ]', 'ا', teh_marbuta_to_heh)\n    kafs_normalized = re.sub(r'ک', 'ك', alifs_normalized)\n    text_cleaned = re.sub(r'[\\u064B-\\u065F]', '', kafs_normalized)\n\n    return text_cleaned","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def process_json_file_nested(file_path, tag_to_int):\n#     with open(file_path, 'r') as file:\n#         data = json.load(file)\n\n#     token_data_layers = []\n#     label_data_layers = []\n#     max_depth = 0\n\n#     for sentence in data:\n#         for token_info in sentence['tokens']:\n#             max_depth = max(max_depth, len(token_info['tags']))\n\n#     for _ in range(max_depth):\n#         token_data_layers.append([])\n#         label_data_layers.append([])\n\n#     for sentence in data:\n#         for depth in range(max_depth):\n#             token_list = []\n#             label_list = []\n#             for token_info in sentence['tokens']:\n#                 token = token_info['token']\n#                 if depth < len(token_info['tags']):\n#                     tag_info = token_info['tags'][depth]\n#                     value = tag_info['value']\n#                 else:\n#                     value = \"O\"\n#                 token_list.append(token)\n#                 label_list.append(tag_to_int[value])\n#             token_data_layers[depth].append(token_list)\n#             label_data_layers[depth].append(label_list)\n\n#     datasets = []\n#     for i in range(max_depth):\n#         datasets.append({'tokens': token_data_layers[i], 'labels': label_data_layers[i]})\n\n#     return datasets","metadata":{"execution":{"iopub.status.busy":"2024-05-06T12:53:47.553751Z","iopub.execute_input":"2024-05-06T12:53:47.554100Z","iopub.status.idle":"2024-05-06T12:53:47.559351Z","shell.execute_reply.started":"2024-05-06T12:53:47.554072Z","shell.execute_reply":"2024-05-06T12:53:47.558383Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def process_json_file_flat(file_path, tag_to_int):\n    with open(file_path, 'r') as file:\n        data = json.load(file)\n\n    token_data = []\n    label_data = []\n    \n    for sentence in data:\n        tokens = []\n        combined_labels = []\n        for token_info in sentence['tokens']:\n            token = token_info['token']\n            tokens.append(token)\n            \n            # Create a combined tag from all layers available for this token\n            tag_combination = '-'.join([tag['value'] for tag in token_info['tags']])\n            if tag_combination not in tag_to_int:\n                tag_to_int[tag_combination] = len(tag_to_int)  # Assign new unique integer if not in dict\n            combined_labels.append(tag_to_int[tag_combination])\n        \n        token_data.append(tokens)\n        label_data.append(combined_labels)\n    \n    return {'tokens': token_data, 'labels': label_data}, tag_to_int\n\n# Use this function to prepare your data\n# combined_dataset, updated_tag_to_int = process_json_file_flat('path_to_your_file.json', {})\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T13:14:36.238180Z","iopub.execute_input":"2024-05-06T13:14:36.238427Z","iopub.status.idle":"2024-05-06T13:14:36.250969Z","shell.execute_reply.started":"2024-05-06T13:14:36.238405Z","shell.execute_reply":"2024-05-06T13:14:36.250151Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"train_path = '/kaggle/input/ner-nested/split70.json'\nvalid_path = '/kaggle/input/ner-nested/split10.json'\ntest_path = '/kaggle/input/nested-ner-test/split20-nested-unlabeled.json'","metadata":{"execution":{"iopub.status.busy":"2024-05-06T13:14:36.252671Z","iopub.execute_input":"2024-05-06T13:14:36.252969Z","iopub.status.idle":"2024-05-06T13:14:36.268513Z","shell.execute_reply.started":"2024-05-06T13:14:36.252947Z","shell.execute_reply":"2024-05-06T13:14:36.267507Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"import json\n\ndef extract_unique_tags(file_paths):\n    unique_tags = set()\n    for file_path in file_paths:\n        with open(file_path, 'r') as file:\n            data = json.load(file)\n            for sentence in data:\n                for token_info in sentence['tokens']:\n                    for tag_info in token_info['tags']:\n                        unique_tags.add(tag_info['value'])\n                        if tag_info.get('tags'):\n                            for nested_tag in tag_info['tags']:\n                                unique_tags.add(nested_tag['value'])\n    return unique_tags\n\ndef calculate_tag_frequencies(labels, label_ids):\n    tag_counts = {}\n    for sublist in labels:\n        for label in sublist:\n            tag_name = label_ids[label]\n            if tag_name in tag_counts:\n                tag_counts[tag_name] += 1\n            else:\n                tag_counts[tag_name] = 1\n    return tag_counts\n\n# Define file paths for your training, validation, and test datasets\nfile_paths = [train_path, valid_path, test_path]\nunique_tags = extract_unique_tags(file_paths)\ntag_to_int = {tag: idx for idx, tag in enumerate(unique_tags)}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T13:14:36.269646Z","iopub.execute_input":"2024-05-06T13:14:36.269993Z","iopub.status.idle":"2024-05-06T13:14:41.106872Z","shell.execute_reply.started":"2024-05-06T13:14:36.269963Z","shell.execute_reply":"2024-05-06T13:14:41.106091Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Load datasets for the first layer only\ntrain_datasets, tag_to_int = process_json_file_flat(train_path, tag_to_int)\nvalid_datasets, _ = process_json_file_flat(valid_path, tag_to_int)\ntest_datasets, _ = process_json_file_flat(test_path, tag_to_int)\nlabel_ids = {idx: label for label, idx in tag_to_int.items()}\ntag_counts = calculate_tag_frequencies(train_datasets['labels'], label_ids)\n\n\ntrain_ds = Dataset.from_dict(train_datasets)\nvalid_ds = Dataset.from_dict(valid_datasets)\ntest_ds = Dataset.from_dict(test_datasets)\n\n# Select the first layer (index 0)\n# train_dataset = train_datasets[0]\n# valid_dataset = valid_datasets[0]\n# test_dataset = test_datasets[0]\n# tag_to_int = {label: idx for idx, label in enumerate(set([lbl for sublist in train_dataset['labels'] for lbl in sublist]))}\n# label_ids = {idx: label for label, idx in tag_to_int.items()}\n\n# train_ds = Dataset.from_dict(train_dataset)\n# valid_ds = Dataset.from_dict(valid_dataset)\n# test_ds = Dataset.from_dict(test_dataset)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T13:14:41.108102Z","iopub.execute_input":"2024-05-06T13:14:41.108452Z","iopub.status.idle":"2024-05-06T13:14:46.639145Z","shell.execute_reply.started":"2024-05-06T13:14:41.108417Z","shell.execute_reply":"2024-05-06T13:14:46.638155Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def tokenize_and_align_labels(examples, label_all_tokens=True):\n    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n    labels = []\n    for i, label in enumerate(examples[\"labels\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx])\n            else:\n                label_ids.append(label[word_idx] if label_all_tokens else -100)\n            previous_word_idx = word_idx\n        labels.append(label_ids)\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2024-05-06T13:14:58.825119Z","iopub.execute_input":"2024-05-06T13:14:58.825490Z","iopub.status.idle":"2024-05-06T13:14:58.832692Z","shell.execute_reply.started":"2024-05-06T13:14:58.825462Z","shell.execute_reply":"2024-05-06T13:14:58.831775Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model_path = \"aubmindlab/bert-base-arabertv2\"\ntokenizer = BertTokenizerFast.from_pretrained(model_path)\ndata_collator = DataCollatorForTokenClassification(tokenizer) \nmetric = datasets.load_metric(\"seqeval\") ","metadata":{"execution":{"iopub.status.busy":"2024-05-06T13:15:00.590877Z","iopub.execute_input":"2024-05-06T13:15:00.591241Z","iopub.status.idle":"2024-05-06T13:15:01.138356Z","shell.execute_reply.started":"2024-05-06T13:15:00.591213Z","shell.execute_reply":"2024-05-06T13:15:01.137455Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize_and_prepare(dataset):\n    return dataset.map(tokenize_and_align_labels, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T13:15:01.541879Z","iopub.execute_input":"2024-05-06T13:15:01.542231Z","iopub.status.idle":"2024-05-06T13:15:01.547839Z","shell.execute_reply.started":"2024-05-06T13:15:01.542198Z","shell.execute_reply":"2024-05-06T13:15:01.545918Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"tokenized_train_ds = train_ds.map(tokenize_and_align_labels, batched=True)\ntokenized_valid_ds = valid_ds.map(tokenize_and_align_labels, batched=True)\ntokenized_test_ds = test_ds.map(tokenize_and_align_labels, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T13:15:01.781917Z","iopub.execute_input":"2024-05-06T13:15:01.782635Z","iopub.status.idle":"2024-05-06T13:15:06.586855Z","shell.execute_reply.started":"2024-05-06T13:15:01.782609Z","shell.execute_reply":"2024-05-06T13:15:06.585993Z"},"trusted":true},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/23125 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36a96138fd7744178853c477edc527ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3304 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6a2f62d4efb4d4986719beb809666e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6606 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"783d4c40a3ce4105be0bee8cfaa31ec7"}},"metadata":{}}]},{"cell_type":"code","source":"def calculate_weights(tag_counts):\n    total_tags = sum(tag_counts.values())\n    weights = {tag: total_tags / count for tag, count in tag_counts.items()}\n\n    max_weight = max(weights.values())\n    weights_normalized = {tag: weight / max_weight for tag, weight in weights.items()}\n\n    return list(weights_normalized.values())\n\nclass_weights = torch.tensor(calculate_weights(tag_counts), dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T13:15:07.863327Z","iopub.execute_input":"2024-05-06T13:15:07.863689Z","iopub.status.idle":"2024-05-06T13:15:07.870228Z","shell.execute_reply.started":"2024-05-06T13:15:07.863661Z","shell.execute_reply":"2024-05-06T13:15:07.869201Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"weighted_loss = nn.CrossEntropyLoss(weight=class_weights)\n\nclass ArabNERModelWithWeightedLoss(AutoModelForTokenClassification):\n    def forward(self, input_ids, attention_mask=None, labels=None, **kwargs):\n        outputs = super().forward(input_ids, attention_mask=attention_mask, **kwargs)\n        if labels is not None:\n            loss = weighted_loss(outputs.logits.view(-1, self.num_labels), labels.view(-1))\n            outputs = (loss,) + outputs[1:]\n        return outputs\n\nmodel = ArabNERModelWithWeightedLoss.from_pretrained(model_path, num_labels=len(label_ids.values()))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T13:15:09.311917Z","iopub.execute_input":"2024-05-06T13:15:09.312286Z","iopub.status.idle":"2024-05-06T13:15:09.624071Z","shell.execute_reply.started":"2024-05-06T13:15:09.312258Z","shell.execute_reply":"2024-05-06T13:15:09.623118Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n# class ArabNERModel(AutoModelForTokenClassification):\n#     def __init__(self, config):\n#         super().__init__(config)\n#         self.loss = nn.CrossEntropyLoss(weight=class_weights)\n\n#     def forward(self, input_ids, attention_mask=None, labels=None, **kwargs):\n#         outputs = super().forward(input_ids, attention_mask=attention_mask, **kwargs)\n#         if labels is not None:\n#             loss = self.loss(outputs.logits.view(-1, self.num_labels), labels.view(-1))\n#             outputs = (loss,) + outputs[1:]\n#         return outputs","metadata":{"execution":{"iopub.status.busy":"2024-05-06T13:15:12.987457Z","iopub.execute_input":"2024-05-06T13:15:12.988191Z","iopub.status.idle":"2024-05-06T13:15:12.992336Z","shell.execute_reply.started":"2024-05-06T13:15:12.988160Z","shell.execute_reply":"2024-05-06T13:15:12.991413Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_list = list(label_ids.values())\ndef compute_metrics(eval_preds): \n    pred_logits, labels = eval_preds \n    pred_logits = np.argmax(pred_logits, axis=2) \n    predictions = [ \n        [label_list[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100] \n        for prediction, label in zip(pred_logits, labels) \n    ] \n    \n    true_labels = [ \n      [label_list[l] for (eval_preds, l) in zip(prediction, label) if l != -100] \n       for prediction, label in zip(pred_logits, labels) \n   ] \n    results = metric.compute(predictions=predictions, references=true_labels) \n    return { \n    \"precision\": results[\"overall_precision\"], \n    \"recall\": results[\"overall_recall\"], \n    \"f1\": results[\"overall_f1\"], \n    \"accuracy\": results[\"overall_accuracy\"], \n  } ","metadata":{"execution":{"iopub.status.busy":"2024-05-06T13:15:13.943093Z","iopub.execute_input":"2024-05-06T13:15:13.943996Z","iopub.status.idle":"2024-05-06T13:15:13.951749Z","shell.execute_reply.started":"2024-05-06T13:15:13.943962Z","shell.execute_reply":"2024-05-06T13:15:13.950742Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"def refine_input_features(model, dataset, tokenizer, tag_to_int):\n    model.eval()  # Set the model to evaluation mode to disable training-specific behaviors\n    refined_datasets = []\n\n#         print(data)\n    tokens = dataset['tokens']  # Accessing tokens directly\n    labels = dataset['labels']  # Accessing labels directly\n\n    # Tokenizing the tokens for model input\n    inputs = tokenizer(tokens, is_split_into_words=True, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n\n    with torch.no_grad():\n        outputs = model(**inputs)\n\n    predictions = outputs.logits.argmax(-1).squeeze().tolist()\n\n    # Select tokens and labels based on predictions not being 'O'\n    refined_tokens = [token for token, pred in zip(tokens, predictions) if tag_to_int[labels[pred]] != tag_to_int['O']]\n    refined_labels = [label for label, pred in zip(labels, predictions) if tag_to_int[label] != tag_to_int['O']]\n\n    refined_datasets.append({'tokens': refined_tokens, 'labels': refined_labels})\n\n    return refined_datasets\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T13:15:14.825435Z","iopub.execute_input":"2024-05-06T13:15:14.826361Z","iopub.status.idle":"2024-05-06T13:15:14.834741Z","shell.execute_reply.started":"2024-05-06T13:15:14.826327Z","shell.execute_reply":"2024-05-06T13:15:14.833604Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# Set up training arguments\nargs = TrainingArguments(\n    \"Results\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=30,\n    weight_decay=0.01,\n    report_to=\"tensorboard\",\n    load_best_model_at_end=True,\n    save_total_limit=5,\n    lr_scheduler_type='linear',\n    warmup_ratio=0.1\n)\n\n# Initialize and train the model\nmodel = ArabNERModel.from_pretrained(model_path, num_labels=len(tag_to_int))\n\ntrainer = Trainer(\n    model,\n    args,\n    train_dataset=tokenized_train_ds,\n    eval_dataset=tokenized_valid_ds,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=8)]\n)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\nmodel = model.to(device)\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T13:15:15.703333Z","iopub.execute_input":"2024-05-06T13:15:15.703971Z","iopub.status.idle":"2024-05-06T13:15:28.257520Z","shell.execute_reply.started":"2024-05-06T13:15:15.703937Z","shell.execute_reply":"2024-05-06T13:15:28.256030Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='68' max='43380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   68/43380 00:10 < 1:57:36, 6.14 it/s, Epoch 0.05/30]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[51], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing device:\u001b[39m\u001b[38;5;124m\"\u001b[39m, device)\n\u001b[1;32m     34\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 35\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1780\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2118\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2121\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2122\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2124\u001b[0m ):\n\u001b[1;32m   2125\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2126\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Evaluate the model\nmetrics = trainer.evaluate(eval_dataset=tokenized_test_ds)\nprint(f\"Evaluation metrics: {metrics}\")\n\n# Save the trained model\nmodel.save_pretrained(\"outer_layer_model\")\ntokenizer.save_pretrained(\"outer_layer_tokenizer\")","metadata":{"execution":{"iopub.status.busy":"2024-05-06T13:15:28.258249Z","iopub.status.idle":"2024-05-06T13:15:28.258609Z","shell.execute_reply.started":"2024-05-06T13:15:28.258436Z","shell.execute_reply":"2024-05-06T13:15:28.258451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from transformers import TrainingArguments, Trainer\n\n# def train_sequential_layers(models, datasets, tokenizer, num_layers, tag_to_int, device):\n#     for layer in range(1, num_layers):  # Start from the second layer\n#         print(f\"Training layer {layer}\")\n#         # Assume refine_input_features returns a list of refined texts\n#         refined_dataset = refine_input_features(models[layer - 1], datasets[layer - 1], tokenizer, tag_to_int)\n\n#         # Prepare the new training dataset\n#         input_ids = tokenizer([data['tokens'] for data in refined_dataset], is_split_into_words=True, return_tensors=\"pt\", padding=True, truncation=True)['input_ids']\n#         labels = [data['labels'] for data in refined_dataset]  # Assuming labels need similar handling\n\n#         # Create Dataset objects for training\n#         train_dataset = Dataset.from_dict({'input_ids': input_ids, 'labels': labels})\n\n#         # Train a new model for this layer\n#         new_model = ArabNERModel.from_pretrained('aubmindlab/bert-base-arabertv2', num_labels=len(tag_to_int))\n#         new_model.to(device)  # Ensure the model is on the correct device\n        \n#         training_args = TrainingArguments(\n#             output_dir=f\"results_layer_{layer}\",\n#             evaluation_strategy=\"epoch\",\n#             learning_rate=2e-5,\n#             per_device_train_batch_size=8,\n#             num_train_epochs=3,\n#             save_strategy=\"no\",\n#             logging_dir=f\"logs_layer_{layer}\"  # Added logging directory for clarity\n#         )\n        \n#         trainer = Trainer(\n#             model=new_model,\n#             args=training_args,\n#             train_dataset=train_dataset,\n#             tokenizer=tokenizer,\n#             callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n#         )\n        \n#         # Train the model\n#         trainer.train()\n#         models.append(new_model)\n\n#     return models\n\n# # Assuming initial_model is pre-trained and ready\n# models = [model]\n# num_layers = 5  # Total number of layers including the initial pre-trained layer\n# trained_models = train_sequential_layers(models, train_datasets[1:], tokenizer, num_layers, tag_to_int, device)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T23:51:21.803084Z","iopub.status.idle":"2024-05-05T23:51:21.803401Z","shell.execute_reply.started":"2024-05-05T23:51:21.803249Z","shell.execute_reply":"2024-05-05T23:51:21.803262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from transformers import TrainingArguments, Trainer\n# # args = TrainingArguments(\n# #     \"Results\",\n# #     evaluation_strategy=\"epoch\",\n# #     save_strategy=\"epoch\",\n# #     learning_rate=2e-5,\n# #     per_device_train_batch_size=16,\n# #     per_device_eval_batch_size=16,\n# #     num_train_epochs=1,\n# #     weight_decay=0.01,\n# #     report_to=\"tensorboard\",\n# #     load_best_model_at_end=True,\n# #     save_total_limit=5,\n# #     lr_scheduler_type='linear',\n# #     warmup_ratio=0.1\n# # )\n\n# # # Initialize and train the model\n# # model = ArabNERModel.from_pretrained(model_path, num_labels=len(tag_to_int))\n\n# # trainer = Trainer(\n# #     model,\n# #     args,\n# #     train_dataset=tokenized_train_ds,\n# #     eval_dataset=tokenized_valid_ds,\n# #     data_collator=data_collator,\n# #     tokenizer=tokenizer,\n# #     compute_metrics=compute_metrics,\n# #     callbacks=[EarlyStoppingCallback(early_stopping_patience=8)]\n# # )\n\n# def train_layer(model, tokenized_train_dataset, tokenized_valid_ds, tokenized_test_ds, tokenizer, layer_index, device):\n#     training_args = TrainingArguments(\n#         f\"Results_{layer_index}\",\n#         evaluation_strategy=\"epoch\",\n#         save_strategy=\"epoch\",\n#         learning_rate=2e-5,\n#         per_device_train_batch_size=16,\n#         per_device_eval_batch_size=16,\n#         num_train_epochs=1,\n#         weight_decay=0.01,\n#         report_to=\"tensorboard\",\n#         load_best_model_at_end=True,\n#         save_total_limit=5,\n#         lr_scheduler_type='linear',\n#         warmup_ratio=0.1\n#     )\n    \n#     trainer = Trainer(\n#         model=model,\n#         args=training_args,\n#         train_dataset=tokenized_train_dataset,\n#         eval_dataset=tokenized_valid_ds,\n#         tokenizer=tokenizer,\n#         compute_metrics=compute_metrics,\n#         callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n#     )\n    \n#     # Train the model\n#     trainer.train()\n#     # Evaluate the model\n#     metrics = trainer.evaluate(eval_dataset=tokenized_test_ds)\n#     print(f\"Evaluation metrics: {metrics}\")\n    \n#     # Save model to disk\n#     model.save_pretrained(f\"saved_model_layer_{layer_index}\")\n    \n#     # Clear memory\n#     del model\n#     torch.cuda.empty_cache()\n\n# def train_sequential_layers(model_paths, train_datasets, validation_datasets, test_datasets, tokenizer, num_layers, device):\n#     models = []\n#     for layer in range(1, num_layers):\n#         print(f\"Training layer {layer}\")\n#         # Load the model for the current layer\n#         model = ArabNERModel.from_pretrained(model_paths[layer - 1])\n        \n#         tokenizer = BertTokenizerFast.from_pretrained(model_paths[layer - 1])\n#         data_collator = DataCollatorForTokenClassification(tokenizer) \n#         model.to(device)\n        \n#         if not train_datasets[layer-1] or not validation_datasets[layer-1] or not test_datasets[layer-1]:\n#             logging.warning(f\"Empty dataset for layer {layer}, skipping training.\")\n#             continue\n        \n#         train_ds = Dataset.from_dict(train_datasets[layer-1])\n#         valid_ds = Dataset.from_dict(validation_datasets[layer-1])\n#         test_ds = Dataset.from_dict(test_datasets[layer-1])\n#         tokenized_train_ds = train_ds.map(tokenize_and_align_labels, batched=True)\n#         tokenized_valid_ds = valid_ds.map(tokenize_and_align_labels, batched=True)\n#         tokenized_test_ds = test_ds.map(tokenize_and_align_labels, batched=True)\n        \n#         # Train the model\n#         train_layer(model, tokenized_train_ds, tokenized_valid_ds, tokenized_test_ds, tokenizer, layer, device)\n        \n#         # Append model path for next layer initialization\n#         models.append(f\"saved_model_layer_{layer}\")\n    \n#     return models\n\n# # Initial model path\n# # initial_model_path = \"initial_model_directory\"\n# # initial_model_path = \"/kaggle/working/Results/runs\"\n# num_layers = 5\n\n# model_paths = [model_path] * (num_layers - 1)  # Paths for later initialized layers\n# print(model_paths)\n# trained_models = train_sequential_layers(model_paths, train_datasets[1:], valid_datasets[1:], test_datasets[1:], tokenizer, num_layers, device)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-05T23:51:21.804632Z","iopub.status.idle":"2024-05-05T23:51:21.804937Z","shell.execute_reply.started":"2024-05-05T23:51:21.804788Z","shell.execute_reply":"2024-05-05T23:51:21.804800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()  # Clear cache before starting the training","metadata":{"execution":{"iopub.status.busy":"2024-05-05T21:31:19.677407Z","iopub.execute_input":"2024-05-05T21:31:19.678133Z","iopub.status.idle":"2024-05-05T21:31:19.682351Z","shell.execute_reply.started":"2024-05-05T21:31:19.678091Z","shell.execute_reply":"2024-05-05T21:31:19.681477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def find_last_created_folder(directory, prefix):\n#     # Ensure the directory exists\n#     if not os.path.exists(directory):\n#         print(f\"The directory {directory} does not exist.\")\n#         return None\n\n#     # List all items in the directory\n#     all_folders = [os.path.join(directory, f) for f in os.listdir(directory)]\n#     # Filter list to include only directories that start with the specified prefix\n#     folders = [folder for folder in all_folders if os.path.isdir(folder) and os.path.basename(folder).startswith(prefix)]\n    \n#     # Check if the list is not empty\n#     if not folders:\n#         print(f\"No folders found in the directory that start with '{prefix}'.\")\n#         return None\n\n#     # Get the last created folder\n#     last_created_folder = max(folders, key=os.path.getctime)\n\n#     return last_created_folder\n\n# # Path to the directory where folders are to be checked\n# directory_path = '/kaggle/working/Results/'\n# folder_prefix = 'checkpoint'  # The prefix to look for in folder names\n# checkpoint_path = find_last_created_folder(directory_path, folder_prefix)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T12:42:06.624858Z","iopub.execute_input":"2024-05-06T12:42:06.625141Z","iopub.status.idle":"2024-05-06T12:42:06.974691Z","shell.execute_reply.started":"2024-05-06T12:42:06.625116Z","shell.execute_reply":"2024-05-06T12:42:06.973460Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m directory_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/Results/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     24\u001b[0m folder_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# The prefix to look for in folder names\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[43mfind_last_created_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_prefix\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[1], line 3\u001b[0m, in \u001b[0;36mfind_last_created_folder\u001b[0;34m(directory, prefix)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_last_created_folder\u001b[39m(directory, prefix):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Ensure the directory exists\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(directory):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe directory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"],"ename":"NameError","evalue":"name 'os' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# from tqdm import tqdm\n# import torch\n\n# def predict_in_batches(model, tokenized_inputs, batch_size=32):\n#     # Check for GPU availability\n#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#     model.to(device)  # Move model to the appropriate device\n#     model.eval()\n    \n#     all_predictions = []\n#     input_ids = tokenized_inputs['input_ids']\n#     attention_mask = tokenized_inputs['attention_mask']\n\n#     # Wrap the range with tqdm for a progress bar\n#     for i in tqdm(range(0, input_ids.size(0), batch_size)):\n#         batch_input_ids = input_ids[i:i + batch_size].to(device)\n#         batch_attention_mask = attention_mask[i:i + batch_size].to(device)\n        \n#         with torch.no_grad():\n#             outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n#             logits = outputs.logits\n#             predictions = logits.argmax(-1)\n        \n#         all_predictions.append(predictions.cpu())  # Move predictions back to CPU if needed\n\n#     return torch.cat(all_predictions, dim=0)\n\n# def map_predictions_to_original_tokens(predictions, tokenized_inputs, label_ids):\n#     word_level_predictions = []\n#     offset_mappings = tokenized_inputs['offset_mapping']\n#     word_ids = [tokenized_inputs.word_ids(batch_index=i) for i in range(predictions.size(0))]\n\n#     for idx, (preds, length) in enumerate(zip(predictions, tokenized_inputs['attention_mask'].sum(1))):\n#         current_word_ids = word_ids[idx]\n#         word_predictions = []\n#         previous_word_idx = None\n#         for word_idx, pred in zip(current_word_ids, preds[:length]):\n#             if word_idx is not None and word_idx != previous_word_idx:\n#                 word_predictions.append(label_ids[pred.item()])\n#             previous_word_idx = word_idx\n#         word_level_predictions.append(word_predictions)\n\n#     return word_level_predictions\n\n# tokenized_inputs = tokenizer(valid_ds['tokens'], is_split_into_words=True, padding=True, truncation=True, return_tensors=\"pt\", return_offsets_mapping=True)\n# predictions = predict_in_batches(test_model, tokenized_inputs, batch_size=16)\n# word_level_predictions = map_predictions_to_original_tokens(predictions, tokenized_inputs, label_ids)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def format_predictions_to_conll(tokens_list, word_level_predictions):\n#     \"\"\"Format the predictions to the CoNLL output format.\"\"\"\n#     output = []\n#     for tokens, predictions in zip(tokens_list, word_level_predictions):\n#         for token, tag in zip(tokens, predictions):\n#             output.append(f\"{token} {tag}\")\n#         output.append(\"\")  # Add a blank line after each sentence for segment separation\n#     return \"\\n\".join(output)\n\n# def write_to_file(content, filename):\n#     \"\"\"Write the given content to a text file.\"\"\"\n#     with open(filename, \"w\", encoding=\"utf-8\") as file:\n#         file.write(content)\n#     print(f\"Data written to {filename}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# conll_output = format_predictions_to_conll(test_ds['tokens'], word_level_predictions)\n# write_to_file(conll_output, \"/kaggle/working/ArabNER_subtask2_valid_pred_2.txt\")","metadata":{},"execution_count":null,"outputs":[]}]}